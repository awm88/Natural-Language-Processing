# -*- coding: utf-8 -*-
"""nlp assignment 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TKnqzb8y1CR5uef7cR3Sn0e5KrnCgjTx
"""

pip install pep8

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

data = pd.read_csv('reviews.csv', delimiter='\t')

data.head()

len(data.dropna())

len(data)

data.info()

data.columns

data.columns=['Skype','Rating','Date','Review'] #naming columns

data.info()

data.Rating.value_counts()

Rating_count=data.groupby('Rating').count()
plt.bar(Rating_count.index.values, Rating_count['Review'])
plt.xlabel('Rating')
plt.ylabel('Number of Review')
plt.show()

def sentiment(n):
  if (n<3): 
    return (0)
  elif (n>3): 
    return 2
  else: 
    return 1
data['sentiment']=data['Rating'].apply(sentiment)
data.head()

data.sentiment.value_counts() #make ratings balanced

index_names = data[ data['sentiment'] == 0 ].index
data.drop(index_names[72:], inplace = True)

print(data)

data.sentiment.value_counts()

index_names = data[ data['sentiment'] == 2 ].index
data.drop(index_names[72:], inplace = True)
#data = data.drop(data.index[72:])

data.sentiment.value_counts() #sentiments are now equal

data.info()

data.tail()

data=data[['sentiment', 'Review']]
data

from sklearn.model_selection import train_test_split
X_train, X_valid, y_train, y_valid = train_test_split(data['Review'], data['sentiment'], test_size=0.4, random_state=24)

X_train,y_train.to_csv("training.csv")

X_valid,y_valid.to_csv("testing.csv")

from sklearn.feature_extraction.text import CountVectorizer #trains model
count_vect = CountVectorizer()
X_train_counts = count_vect.fit_transform(X_train)
X_train_counts.shape

from sklearn.feature_extraction.text import TfidfTransformer
tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)
X_train_tf = tf_transformer.transform(X_train_counts)
X_train_tf.shape

tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)
X_train_tfidf.shape

from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB().fit(X_train_tfidf, y_train)

from sklearn.pipeline import Pipeline
text_clf = Pipeline([
    ('vect', CountVectorizer()),
    ('tfidf', TfidfTransformer()),
    ('clf', MultinomialNB()),
])

text_clf.fit(X_train, y_train)

predicted = text_clf.predict(X_valid)
np.mean(predicted == y_valid)

from sklearn.linear_model import SGDClassifier
text_clf = Pipeline([
    ('vect', CountVectorizer()),
    ('tfidf', TfidfTransformer()),
    ('clf', SGDClassifier(loss='hinge', penalty='l2',
                          alpha=1e-3, random_state=42,
                          max_iter=5, tol=None)),
])

text_clf.fit(X_train, y_train)

predicted = text_clf.predict(X_valid)
np.mean(predicted == y_valid)

from sklearn import metrics #performance metrics
print(metrics.classification_report(y_valid, predicted, target_names={'Positive':2, 'Negative':0, 'Neutral':1}))

metrics.confusion_matrix(y_valid, predicted) #confusion matrix

#positive for the first column, negative for the second column and neutral for the third means that 16 postitive reviews were predicted
#20 were predicted correctly for negative reviews, and 23 were correctly predicted for neutral reviews. This is the total of 89 reviews in the test set.